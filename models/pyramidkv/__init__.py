"""
PyramidKV: Efficient KV-Cache management for LLM inference.

This package provides various KV-cache compression methods including:
- PyramidKV: Hierarchical compression
- SnapKV: Attention-based pruning  
- H2O: Heavy-hitter oracle
- StreamingLLM: Streaming attention
- AdaKV: Adaptive compression
- HeadKV: Head-wise compression
- CAM: Channel attention module
- L2Norm: L2 normalization based pruning
"""